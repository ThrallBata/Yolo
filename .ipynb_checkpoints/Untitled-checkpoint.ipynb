{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bccd3b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     28\u001b[0m     _, image \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m---> 30\u001b[0m     h, w \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     31\u001b[0m     blob \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mdnn\u001b[38;5;241m.\u001b[39mblobFromImage(image, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.0\u001b[39m, (\u001b[38;5;241m416\u001b[39m, \u001b[38;5;241m416\u001b[39m), swapRB\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, crop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     32\u001b[0m     net\u001b[38;5;241m.\u001b[39msetInput(blob)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "CONFIDENCE = 0.5\n",
    "SCORE_THRESHOLD = 0.5\n",
    "IOU_THRESHOLD = 0.5\n",
    "config_path = \"cfg/yolov3.cfg\"\n",
    "weights_path = \"weights/yolov3.weights\"\n",
    "font_scale = 1\n",
    "thickness = 1\n",
    "labels = open(\"data/coco.names\").read().strip().split(\"\\n\")\n",
    "colors = np.random.randint(0, 255, size=(len(labels), 3), dtype=\"uint8\")\n",
    "\n",
    "net = cv2.dnn.readNetFromDarknet(config_path, weights_path)\n",
    "\n",
    "ln = net.getLayerNames()\n",
    "try:\n",
    "    ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "except IndexError:\n",
    "    # in case getUnconnectedOutLayers() returns 1D array when CUDA isn't available\n",
    "    ln = [ln[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _, image = cap.read()\n",
    "\n",
    "    h, w = image.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(image, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    start = time.perf_counter()\n",
    "    layer_outputs = net.forward(ln)\n",
    "    time_took = time.perf_counter() - start\n",
    "    print(\"Time took:\", time_took)\n",
    "    boxes, confidences, class_ids = [], [], []\n",
    "\n",
    "    # loop over each of the layer outputs\n",
    "    for output in layer_outputs:\n",
    "        # перебираем все обнаруженные объекты\n",
    "        for detection in output:\n",
    "            # извлекаем идентификатор класса (метку) и достоверность (как вероятность)\n",
    "            # обнаружение текущего объекта\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            # отбросим слабые прогнозы, убедившись, что у обнаруженных\n",
    "            # вероятность больше минимальной вероятности\n",
    "            if confidence > CONFIDENCE:\n",
    "                # масштабируем координаты ограничивающего прямоугольника относительно\n",
    "                # размер изображения, учитывая, что YOLO на самом деле\n",
    "                # возвращает центральные координаты (x, y) ограничивающего\n",
    "                # поля, за которым следуют ширина и высота полей\n",
    "                box = detection[:4] * np.array([w, h, w, h])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "\n",
    "                # используем центральные координаты (x, y) для получения вершины и\n",
    "                # и левый угол ограничительной рамки\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "\n",
    "                # обновить наш список координат ограничивающего прямоугольника, достоверности,\n",
    "                # и идентификаторы класса\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    # выполнить не максимальное подавление с учетом оценок, определенных ранее\n",
    "    idxs = cv2.dnn.NMSBoxes(boxes, confidences, SCORE_THRESHOLD, IOU_THRESHOLD)\n",
    "\n",
    "    font_scale = 1\n",
    "    thickness = 1\n",
    "\n",
    "    # убедитесь, что существует хотя бы один обнаруженный объект\n",
    "    if len(idxs) > 0:\n",
    "        # перебираем сохраняемые индексы\n",
    "        for i in idxs.flatten():\n",
    "            # извлекаем координаты ограничивающего прямоугольника\n",
    "            x, y = boxes[i][0], boxes[i][1]\n",
    "            w, h = boxes[i][2], boxes[i][3]\n",
    "            # рисуем прямоугольник ограничивающей рамки и подписываем на изображении\n",
    "            color = [int(c) for c in colors[class_ids[i]]]\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), color=color, thickness=thickness)\n",
    "            text = f\"{labels[class_ids[i]]}: {confidences[i]:.2f}\"\n",
    "            # вычисляем ширину и высоту текста, чтобы рисовать прозрачные поля в качестве фона текста\n",
    "            (text_width, text_height) = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, fontScale=font_scale, thickness=thickness)[0]\n",
    "            text_offset_x = x\n",
    "            text_offset_y = y - 5\n",
    "            box_coords = ((text_offset_x, text_offset_y), (text_offset_x + text_width + 2, text_offset_y - text_height))\n",
    "            overlay = image.copy()\n",
    "            cv2.rectangle(overlay, box_coords[0], box_coords[1], color=color, thickness=cv2.FILLED)\n",
    "            # добавить непрозрачность (прозрачность поля)\n",
    "            image = cv2.addWeighted(overlay, 0.6, image, 0.4, 0)\n",
    "            # теперь поместите текст (метка: доверие%)\n",
    "            cv2.putText(image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                fontScale=font_scale, color=(0, 0, 0), thickness=thickness)\n",
    "\n",
    "    cv2.imshow(\"image\", image)\n",
    "    if ord(\"q\") == cv2.waitKey(1):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6691b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
